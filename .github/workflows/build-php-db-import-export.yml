on:
  workflow_call:
    inputs:
      hasCodeChanged:
        required: true
        type: boolean
      isTag:
        required: true
        type: boolean
      isRequiredRepoChanged:
        required: true
        type: boolean
    secrets:
      AWS_SECRET_ACCESS_KEY:
        required: true
      ABS_ACCOUNT_KEY:
        required: true
      SNOWFLAKE_PASSWORD:
        required: true
      SYNAPSE_PWD:
        required: true
      AZURE_CLIENT_SECRET:
        required: true
      TERADATA_PASSWORD:
        required: true
      ABS_TERADATA_PASSWORD:
        required: true
      EXASOL_PASSWORD:
        required: true
      EXA_SAAS_TOKEN:
        required: true
      OAUTH_TOKEN_GITHUB:
        required: true
      GCS_CREDENTIALS:
        required: true
      BQ_KEY_FILE:
        required: true
      SYNAPSE_PRINCIPAL_PASSWORD:
        required: true

concurrency: build-php-db-import-export

env:
  BUILD_PREFIX: gh
  PHP_VERSION_E2E: '8.1'
  # Snowflake
  SNOWFLAKE_HOST: keboolaconnectiondev.us-east-1.snowflakecomputing.com
  SNOWFLAKE_PORT: 443
  SNOWFLAKE_USER: KEBOOLA_CI_PHP_IE_LIB
  SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
  SNOWFLAKE_DATABASE: KEBOOLA_CI_PHP_IE_LIB
  SNOWFLAKE_WAREHOUSE: DEV
  # Synapse
  SYNAPSE_UID: keboola
  SYNAPSE_PWD: ${{ secrets.SYNAPSE_PWD }}
  SYNAPSE_DATABASE: ci-php-ei-lib-gh-db-7nybfrempo4vcbd4248b7ca
  SYNAPSE_SERVER: ci-php-ei-lib-gh-sql-7nybfrempo4vcbd4248b7ca.database.windows.net
  SYNAPSE_SQL_SERVER_NAME: ci-php-ei-lib-gh-sql-7nybfrempo4vcbd4248b7ca
  SYNAPSE_DW_SERVER_NAME: ci-php-ei-lib-gh-db-7nybfrempo4vcbd4248b7ca
  SYNAPSE_PRINCIPAL_TENANT: 9b85ee6f-4fb0-4a46-8cb7-4dcc6b262a89
  SYNAPSE_PRINCIPAL: 355a3e15-5251-42a9-8266-85c3e17ae82d
  SYNAPSE_PRINCIPAL_PASSWORD: ${{ secrets.SYNAPSE_PRINCIPAL_PASSWORD }}
  AZURE_RESOURCE_GROUP: ci-import-export-lib
  SYNAPSE_RESOURCE_GROUP: ci-import-export-lib
  # Teradata
  TERADATA_HOST: 20.105.40.100
  TERADATA_USERNAME: ci_ielib
  TERADATA_PASSWORD: ${{ secrets.TERADATA_PASSWORD }}
  TERADATA_PORT: 1025
  TERADATA_DATABASE: ci_ielib
  # Teradata for ABS
  ABS_TERADATA_HOST: 20.67.225.211
  ABS_TERADATA_USERNAME: ci_ielib_abs
  ABS_TERADATA_PASSWORD: ${{ secrets.ABS_TERADATA_PASSWORD }}
  ABS_TERADATA_PORT: 1025
  ABS_TERADATA_DATABASE: ci_ielib_abs
  # Exasol
  EXASOL_HOST: mbgghigkizhshorgb53ivhkrsu.clusters.exasol.com:8563
  EXASOL_USERNAME: devel
  EXASOL_PASSWORD: ${{ secrets.EXASOL_PASSWORD }}
  EXA_SAAS_DB_ID: 5ThvKt2NQEqTf-QVEBcNeg
  EXA_SAAS_HOST: https://cloud.exasol.com
  EXA_SAAS_USER_ID: oAVqZoHnSRO5rAjahTgAkg
  EXA_SAAS_TOKEN: ${{ secrets.EXA_SAAS_TOKEN }}
  # Bigquery
  BQ_KEY_FILE: ${{ secrets.BQ_KEY_FILE }}
  BQ_BUCKET_NAME: ie-ci-files-bucket
  # S3
  AWS_ACCESS_KEY_ID: AKIASFZVQM6IHFATWR4X
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_S3_BUCKET: ci-php-ie-lib
  AWS_S3_KEY: ${{ github.run_id }}-${{ github.run_number }}
  AWS_REGION: us-east-1
  # ABS
  ABS_ACCOUNT_KEY: ${{ secrets.ABS_ACCOUNT_KEY }}
  ABS_ACCOUNT_NAME: 7nybfrempo4vcbd4248b7ca
  ABS_CONTAINER_NAME: ${{ github.run_id }}-${{ github.run_number }}
  GITHUB_OAUTH_TOKEN: ${{ secrets.OAUTH_TOKEN_GITHUB }}
  #GCS
  GCS_BUCKET_NAME: ie-ci-lib
  GCS_CREDENTIALS: ${{ secrets.GCS_CREDENTIALS }}
  GCS_INTEGRATION_NAME: CI_PHP_IE_LIB

jobs:
  build:
    if: ${{ inputs.hasCodeChanged || inputs.isTag || inputs.isRequiredRepoChanged }}
    permissions:
      id-token: write
      contents: read
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        php-version:
          - '7.4'
          - '8.1'
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          role-to-assume: arn:aws:iam::149899208592:role/ci-storage-backend-BaseStorageBackendRole-5WXOY9DYENCT
          aws-region: us-east-1

      - name: Download artifact
        uses: actions/download-artifact@v3
        with:
          name: ci-monorepo
          path: /tmp
      - name: Load Base monorepo Docker image
        run: |
          docker load --input /tmp/ci-monorepo.tar
      - name: Monorepo Localize Composer Paths
        run: |
          docker-compose run ci-monorepo composer install
          docker-compose run ci-monorepo vendor/bin/monorepo-builder localize-composer-paths packages/php-db-import-export/composer.json --ansi
      -
        name: Build docker image
        if: ${{ matrix.php-version != env.PHP_VERSION_E2E }}
        env:
          DOCKER_BUILDKIT: 1
        run: |
          docker-compose build --build-arg PHP_VERSION=${{ matrix.php-version }} ci-php-db-import-export
      -
        name: Build docker image
        if: ${{ matrix.php-version == env.PHP_VERSION_E2E }}
        env:
          DOCKER_BUILDKIT: 1
        run: |
          docker-compose build --build-arg PHP_VERSION=${{ matrix.php-version }} ci-php-db-import-export
          docker save -o /tmp/ci-php-db-import-export.tar ci-php-db-import-export:latest
      -
        name: Check
        if: ${{ matrix.php-version != env.PHP_VERSION_E2E }}
        run: |
          docker-compose run ci-php-db-import-export php -v
          docker-compose run ci-php-db-import-export composer ci
      -
        name: Upload docker image
        if: ${{ matrix.php-version == env.PHP_VERSION_E2E }}
        uses: actions/upload-artifact@v3
        with:
          name: ci-php-db-import-export
          path: /tmp/ci-php-db-import-export.tar

  # Load stubs to S3/ABS
  load-s3:
    runs-on: ubuntu-latest
    needs: build
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v3
        with:
          name: ci-php-db-import-export
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/ci-php-db-import-export.tar
      -
        name: Load data to ${{ matrix.storage }}
        run: |
          docker-compose run ci-php-db-import-export composer loadS3
  load-abs:
    runs-on: ubuntu-latest
    needs: build
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v3
        with:
          name: ci-php-db-import-export
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/ci-php-db-import-export.tar
      -
        name: Load data to ${{ matrix.storage }}
        run: |
          docker-compose run ci-php-db-import-export composer loadAbs
  load-gcs:
    runs-on: ubuntu-latest
    needs: build
    strategy:
      matrix:
        suite:
          - snowflake
          - bigquery
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v3
        with:
          name: ci-php-db-import-export
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/ci-php-db-import-export.tar
      -
        name: Load data to ${{ matrix.storage }}
        run: |
          docker-compose run ci-php-db-import-export composer loadGcs-${{ matrix.suite }}

  # Test matrix
  testsABS:
    runs-on: ubuntu-latest
    needs: load-abs
    concurrency: ${{ matrix.suite }}
    strategy:
      fail-fast: false
      matrix:
        suite:
          - snowflake-abs
          - teradata-tpt-abs
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v3
        with:
          name: ci-php-db-import-export
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/ci-php-db-import-export.tar
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run ci-php-db-import-export composer tests-${{ matrix.suite }}
  testsS3:
    runs-on: ubuntu-latest
    needs: load-s3
    concurrency: ${{ matrix.suite }}
    strategy:
      fail-fast: false
      matrix:
        suite:
          - snowflake-s3
          - teradata-tpt-s3
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v3
        with:
          name: ci-php-db-import-export
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/ci-php-db-import-export.tar
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run ci-php-db-import-export composer tests-${{ matrix.suite }}
  testsGCS:
    runs-on: ubuntu-latest
    needs: load-gcs
    concurrency: ${{ matrix.suite }}
    strategy:
      fail-fast: false
      matrix:
        suite:
          - snowflake-gcs
          - bigquery
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v3
        with:
          name: ci-php-db-import-export
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/ci-php-db-import-export.tar
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run ci-php-db-import-export composer tests-${{ matrix.suite }}
  testsAll:
    runs-on: ubuntu-latest
    needs: [load-s3, load-abs]
    concurrency: ${{ matrix.suite }}
    strategy:
      fail-fast: false
      matrix:
        suite:
          - storage
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v3
        with:
          name: ci-php-db-import-export
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/ci-php-db-import-export.tar
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run ci-php-db-import-export composer tests-${{ matrix.suite }}

  pre-synapse-tests:
    runs-on: ubuntu-latest
    needs: build
    concurrency: synapse-tests
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Synapse start
        run: |
          bash ./provisioning/scripts/synapseRun.sh -r || exit 1
          bash ./provisioning/scripts/synapseRun.sh -w || exit 1

  synapse-tests:
    runs-on: ubuntu-latest
    needs: [load-abs, pre-synapse-tests]
    strategy:
      fail-fast: false
      matrix:
        suite:
          - synapse
          - synapse-mi
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v3
        with:
          name: ci-php-db-import-export
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/ci-php-db-import-export.tar
      #
      # TESTS
      #
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run ci-php-db-import-export composer tests-${{ matrix.suite }}
  post-synapse-tests:
    runs-on: ubuntu-latest
    needs: synapse-tests
    if: ${{ inputs.hasCodeChanged || inputs.isTag || inputs.isRequiredRepoChanged }}
    concurrency: synapse-tests
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Synapse stop
        if: ${{ always() }}
        run: |
          bash ./provisioning/scripts/synapseRun.sh -p || exit 1

  #  pre-exasol-tests:
  #    runs-on: ubuntu-latest
  #    needs: build
  #    concurrency: exasol-tests
  #    steps:
  #      -
  #        name: Checkout
  #        uses: actions/checkout@v3
  #      -
  #        name: Exasol start
  #        run: |
  #          bash ./docker/exasol/createDeleteServer.sh -w || exit 1

  exasol-tests:
    runs-on: ubuntu-latest
    needs: [load-s3]
    strategy:
      fail-fast: false
      matrix:
        suite:
          - exasol
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v3
        with:
          name: ci-php-db-import-export
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/ci-php-db-import-export.tar
      #
      # TESTS
      #
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run ci-php-db-import-export composer tests-${{ matrix.suite }}
  #  post-exasol-tests:
  #    runs-on: ubuntu-latest
  #    needs: exasol-tests
  #    if: ${{ always() }}
  #    concurrency: exasol-tests
  #    steps:
  #      -
  #        name: Checkout
  #        uses: actions/checkout@v3
  #      -
  #        name: Exasol stop
  #        if: ${{ always() }}
  #        run: |
  #          bash ./docker/exasol/createDeleteServer.sh -p || exit 1

  #
  # Clean up uploaded data
  clean-s3:
    runs-on: ubuntu-latest
    needs: [testsS3, testsAll, exasol-tests]
    if: ${{ inputs.hasCodeChanged || inputs.isTag || inputs.isRequiredRepoChanged }}
    steps:
      -
        name: 'Clean S3'
        run: |
          aws s3 rm s3://${{ env.AWS_S3_BUCKET }}/${{env.AWS_S3_KEY}} --recursive
  clean-gcs-snowflake:
    runs-on: ubuntu-latest
    needs: [testsGCS, testsAll]
    if: ${{ inputs.hasCodeChanged || inputs.isTag || inputs.isRequiredRepoChanged }}
    steps:
      - uses: 'actions/checkout@v3'
      -
        name: 'Login GCS'
        uses: 'google-github-actions/auth@v0'
        with:
          credentials_json: '${{ env.GCS_CREDENTIALS }}'
      -
        name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v0'
      -
        name: 'Clean GCS'
        run: 'gsutil -m rm -r gs://${{env.GCS_BUCKET_NAME}}/*'
  clean-gcs-bigquery:
    runs-on: ubuntu-latest
    needs: [ testsGCS, testsAll ]
    if: ${{ inputs.hasCodeChanged || inputs.isTag || inputs.isRequiredRepoChanged }}
    steps:
      - uses: 'actions/checkout@v3'
      - name: 'Login GCS'
        uses: 'google-github-actions/auth@v0'
        with:
          credentials_json: '${{ env.BQ_KEY_FILE }}'
      - name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v0'
      - name: 'Clean GCS'
        run: 'gsutil -m rm -r gs://${{env.BQ_BUCKET_NAME}}/*'
  clean-abs:
    runs-on: ubuntu-latest
    needs: [testsABS, testsAll, synapse-tests]
    if: ${{ inputs.hasCodeChanged || inputs.isTag || inputs.isRequiredRepoChanged }}
    steps:
      -
        name: 'Install azure cli'
        run: 'curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash'
      -
        name: 'Clean blob storage'
        run: |
          az storage container delete \
          --account-key ${{ env.ABS_ACCOUNT_KEY }} \
          --account-name ${{ env.ABS_ACCOUNT_NAME }} \
          --name ${{ env.ABS_CONTAINER_NAME }}
