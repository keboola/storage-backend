name: Tests

on:
  push:
    branches:
      - master
  pull_request:

concurrency: tests

env:
  BUILD_PREFIX: gh
  PHP_VERSION_E2E: '8.1'
  # Snowflake
  SNOWFLAKE_HOST: keboolaconnectiondev.us-east-1.snowflakecomputing.com
  SNOWFLAKE_PORT: 443
  SNOWFLAKE_USER: KEBOOLA_CI_PHP_IE_LIB
  SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
  SNOWFLAKE_DATABASE: KEBOOLA_CI_PHP_IE_LIB
  SNOWFLAKE_WAREHOUSE: DEV
  # Synapse
  SYNAPSE_UID: keboola
  SYNAPSE_PWD: ${{ secrets.SYNAPSE_PWD }}
  SYNAPSE_DATABASE: ci-php-ei-lib-gh-db-7nybfrempo4vcbd4248b7ca
  SYNAPSE_SERVER: ci-php-ei-lib-gh-sql-7nybfrempo4vcbd4248b7ca.database.windows.net
  SYNAPSE_SQL_SERVER_NAME: ci-php-ei-lib-gh-sql-7nybfrempo4vcbd4248b7ca
  SYNAPSE_DW_SERVER_NAME: ci-php-ei-lib-gh-db-7nybfrempo4vcbd4248b7ca
  SYNAPSE_PRINCIPAL_TENANT: 9b85ee6f-4fb0-4a46-8cb7-4dcc6b262a89
  SYNAPSE_PRINCIPAL: 355a3e15-5251-42a9-8266-85c3e17ae82d
  SYNAPSE_PRINCIPAL_PASSWORD: ${{ secrets.AZURE_CLIENT_SECRET }}
  AZURE_RESOURCE_GROUP: ci-import-export-lib
  SYNAPSE_RESOURCE_GROUP: ci-import-export-lib
  # Teradata
  TERADATA_HOST: 20.105.40.100
  TERADATA_USERNAME: ci_ielib
  TERADATA_PASSWORD: ${{ secrets.TERADATA_PASSWORD }}
  TERADATA_PORT: 1025
  TERADATA_DATABASE: ci_ielib
  # Teradata for ABS
  ABS_TERADATA_HOST: 20.67.225.211
  ABS_TERADATA_USERNAME: ci_ielib_abs
  ABS_TERADATA_PASSWORD: ${{ secrets.ABS_TERADATA_PASSWORD }}
  ABS_TERADATA_PORT: 1025
  ABS_TERADATA_DATABASE: ci_ielib_abs
  # Exasol
  EXASOL_HOST: mbgghigkizhshorgb53ivhkrsu.clusters.exasol.com:8563
  EXASOL_USERNAME: devel
  EXASOL_PASSWORD: ${{ secrets.EXASOL_PASSWORD }}
  EXA_SAAS_DB_ID: 5ThvKt2NQEqTf-QVEBcNeg
  EXA_SAAS_HOST: https://cloud.exasol.com
  EXA_SAAS_USER_ID: oAVqZoHnSRO5rAjahTgAkg
  EXA_SAAS_TOKEN: ${{ secrets.EXA_SAAS_TOKEN }}
  # Bigquery
  BQ_KEY_FILE: ${{ secrets.BQ_KEY_FILE }}
  BQ_BUCKET_NAME: ci-files-bucket
  # S3
  AWS_ACCESS_KEY_ID: AKIASFZVQM6IHFATWR4X
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_S3_BUCKET: ci-php-ie-lib
  AWS_S3_KEY: ${{ github.run_id }}-${{ github.run_number }}
  AWS_REGION: us-east-1
  # ABS
  ABS_ACCOUNT_KEY: ${{ secrets.ABS_ACCOUNT_KEY }}
  ABS_ACCOUNT_NAME: 7nybfrempo4vcbd4248b7ca
  ABS_CONTAINER_NAME: ${{ github.run_id }}-${{ github.run_number }}
  GITHUB_OAUTH_TOKEN: ${{ secrets.OAUTH_TOKEN_GITHUB }}
  #GCS
  GCS_BUCKET_NAME: ci-import-export-lib
  GCS_CREDENTIALS: ${{ secrets.GCS_CREDENTIALS }}
  GCS_INTEGRATION_NAME: CI_PHP_IE_LIB

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        php-version:
          - '7.4'
          - '8.1'
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Build docker image
        if: ${{ matrix.php-version != env.PHP_VERSION_E2E }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BUILD_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BUILD_AWS_SECRET_ACCESS_KEY }}
        run: |
          docker-compose build --build-arg PHP_VERSION=${{ matrix.php-version }} production
      -
        name: Build docker image
        if: ${{ matrix.php-version == env.PHP_VERSION_E2E }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BUILD_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BUILD_AWS_SECRET_ACCESS_KEY }}
        run: |
          docker-compose build --build-arg PHP_VERSION=${{ matrix.php-version }} production
          docker save -o /tmp/image.tar php-db-import-export_production:latest
      -
        name: Check
        if: ${{ matrix.php-version != env.PHP_VERSION_E2E }}
        run: |
          docker-compose run production php -v
          docker-compose run production composer ci
      -
        name: Upload docker image
        if: ${{ matrix.php-version == env.PHP_VERSION_E2E }}
        uses: actions/upload-artifact@v2
        with:
          name: image
          path: /tmp/image.tar
#
# Load stubs to S3/ABS
  load-s3:
    runs-on: ubuntu-latest
    needs: build
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      -
        name: Load data to ${{ matrix.storage }}
        run: |
          docker-compose run production composer loadS3
  load-abs:
    runs-on: ubuntu-latest
    needs: build
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      -
        name: Load data to ${{ matrix.storage }}
        run: |
          docker-compose run production composer loadAbs
  load-gcs:
    runs-on: ubuntu-latest
    needs: build
    strategy:
      matrix:
        suite:
          - snowflake
          - bigquery
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      -
        name: Load data to ${{ matrix.storage }}
        run: |
          docker-compose run production composer loadGcs-${{ matrix.suite }}
#
# Test matrix
  testsABS:
    runs-on: ubuntu-latest
    needs: load-abs
    concurrency: ${{ matrix.suite }}
    strategy:
      fail-fast: false
      matrix:
        suite:
          - snowflake-abs
          - teradata-tpt-abs
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run production composer tests-${{ matrix.suite }}
  testsS3:
    runs-on: ubuntu-latest
    needs: load-s3
    concurrency: ${{ matrix.suite }}
    strategy:
      fail-fast: false
      matrix:
        suite:
          - snowflake-s3
          - teradata-tpt-s3
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run production composer tests-${{ matrix.suite }}
  testsGCS:
    runs-on: ubuntu-latest
    needs: load-gcs
    concurrency: ${{ matrix.suite }}
    strategy:
      fail-fast: false
      matrix:
        suite:
          - snowflake-gcs
          - bigquery
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run production composer tests-${{ matrix.suite }}
  testsAll:
    runs-on: ubuntu-latest
    needs: [load-s3, load-abs]
    concurrency: ${{ matrix.suite }}
    strategy:
      fail-fast: false
      matrix:
        suite:
          - storage
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run production composer tests-${{ matrix.suite }}

  pre-synapse-tests:
    runs-on: ubuntu-latest
    needs: build
    concurrency: synapse-tests
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Synapse start
        run: |
          bash ./provisioning/scripts/synapseRun.sh -r || exit 1
          bash ./provisioning/scripts/synapseRun.sh -w || exit 1

  synapse-tests:
    runs-on: ubuntu-latest
    needs: [load-abs, pre-synapse-tests]
    strategy:
      fail-fast: false
      matrix:
        suite:
          - synapse
          - synapse-mi
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      #
      # TESTS
      #
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run production composer tests-${{ matrix.suite }}
  post-synapse-tests:
    runs-on: ubuntu-latest
    needs: synapse-tests
    if: ${{ always() }}
    concurrency: synapse-tests
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Synapse stop
        if: ${{ always() }}
        run: |
          bash ./provisioning/scripts/synapseRun.sh -p || exit 1
#
#  pre-exasol-tests:
#    runs-on: ubuntu-latest
#    needs: build
#    concurrency: exasol-tests
#    steps:
#      -
#        name: Checkout
#        uses: actions/checkout@v3
#      -
#        name: Exasol start
#        run: |
#          bash ./docker/exasol/createDeleteServer.sh -w || exit 1

  exasol-tests:
    runs-on: ubuntu-latest
    needs: [load-s3]
    strategy:
      fail-fast: false
      matrix:
        suite:
          - exasol
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      #
      # TESTS
      #
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run production composer tests-${{ matrix.suite }}
#  post-exasol-tests:
#    runs-on: ubuntu-latest
#    needs: exasol-tests
#    if: ${{ always() }}
#    concurrency: exasol-tests
#    steps:
#      -
#        name: Checkout
#        uses: actions/checkout@v3
#      -
#        name: Exasol stop
#        if: ${{ always() }}
#        run: |
#          bash ./docker/exasol/createDeleteServer.sh -p || exit 1

#
# Clean up uploaded data
  clean-s3:
    runs-on: ubuntu-latest
    needs: [testsS3, testsAll, exasol-tests]
    if: ${{ always() }}
    steps:
      -
        name: 'Clean S3'
        run: |
          aws s3 rm s3://${{ env.AWS_S3_BUCKET }}/${{env.AWS_S3_KEY}} --recursive
  clean-gcs-snowflake:
    runs-on: ubuntu-latest
    needs: [testsGCS, testsAll]
    if: ${{ always() }}
    steps:
      -
        name: 'Login GCS'
        uses: 'google-github-actions/auth@v0'
        with:
          credentials_json: '${{ env.GCS_CREDENTIALS }}'
      -
        name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v0'
      -
        name: 'Clean GCS'
        run: 'gsutil -m rm -r gs://${{env.GCS_BUCKET_NAME}}/*'
  clean-gcs-bigquery:
    runs-on: ubuntu-latest
    needs: [ testsGCS, testsAll ]
    if: ${{ always() }}
    steps:
      - name: 'Login GCS'
        uses: 'google-github-actions/auth@v0'
        with:
          credentials_json: '${{ env.BQ_KEY_FILE }}'
      - name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v0'
      - name: 'Clean GCS'
        run: 'gsutil -m rm -r gs://${{env.BQ_BUCKET_NAME}}/*'
  clean-abs:
    runs-on: ubuntu-latest
    needs: [testsABS, testsAll, synapse-tests]
    if: ${{ always() }}
    steps:
      -
        name: 'Install azure cli'
        run: 'curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash'
      -
        name: 'Clean blob storage'
        run: |
            az storage container delete \
            --account-key ${{ env.ABS_ACCOUNT_KEY }} \
            --account-name ${{ env.ABS_ACCOUNT_NAME }} \
            --name ${{ env.ABS_CONTAINER_NAME }}
