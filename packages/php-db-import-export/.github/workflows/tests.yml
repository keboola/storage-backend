name: Tests

on:
  push:
    branches:
      - master
  pull_request:

concurrency: tests

env:
  TEST_PREFIX: gh_
  # Snowflake
  SNOWFLAKE_HOST: keboolaconnectiondev.us-east-1.snowflakecomputing.com
  SNOWFLAKE_PORT: 443
  SNOWFLAKE_USER: KEBOOLA_CI_PHP_IE_LIB
  SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
  SNOWFLAKE_DATABASE: KEBOOLA_CI_PHP_IE_LIB
  SNOWFLAKE_WAREHOUSE: DEV
  # Synapse
  SYNAPSE_UID: keboola
  SYNAPSE_PWD: ${{ secrets.SYNAPSE_PWD }}
  SYNAPSE_DATABASE: ci-php-ei-lib-gh-db-7nybfrempo4vcbd4248b7ca
  SYNAPSE_SERVER: ci-php-ei-lib-gh-sql-7nybfrempo4vcbd4248b7ca.database.windows.net
  SYNAPSE_SQL_SERVER_NAME: ci-php-ei-lib-gh-sql-7nybfrempo4vcbd4248b7ca
  SYNAPSE_DW_SERVER_NAME: ci-php-ei-lib-gh-db-7nybfrempo4vcbd4248b7ca
  SYNAPSE_PRINCIPAL_TENANT: 9b85ee6f-4fb0-4a46-8cb7-4dcc6b262a89
  SYNAPSE_PRINCIPAL: 355a3e15-5251-42a9-8266-85c3e17ae82d
  SYNAPSE_PRINCIPAL_PASSWORD: ${{ secrets.AZURE_CLIENT_SECRET }}
  AZURE_RESOURCE_GROUP: ci-import-export-lib
  SYNAPSE_RESOURCE_GROUP: ci-import-export-lib
  # Teradata
  TERADATA_HOST: 20.105.40.100
  TERADATA_USERNAME: ci_ielib
  TERADATA_PASSWORD: ${{ secrets.TERADATA_PASSWORD }}
  TERADATA_PORT: 1025
  TERADATA_DATABASE: ci_ielib
  # Exasol
  EXASOL_HOST: mbgghigkizhshorgb53ivhkrsu.clusters.exasol.com:8563
  EXASOL_USERNAME: devel
  EXASOL_PASSWORD: ${{ secrets.EXASOL_PASSWORD }}
  EXA_SAAS_DB_ID: 5ThvKt2NQEqTf-QVEBcNeg
  EXA_SAAS_HOST: https://cloud.exasol.com
  EXA_SAAS_USER_ID: oAVqZoHnSRO5rAjahTgAkg
  EXA_SAAS_TOKEN: ${{ secrets.EXA_SAAS_TOKEN }}
  # S3
  AWS_ACCESS_KEY_ID: AKIASFZVQM6IHFATWR4X
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_S3_BUCKET: ci-php-ie-lib
  AWS_S3_KEY: ${{ github.run_id }}-${{ github.run_number }}
  AWS_REGION: us-east-1
  # ABS
  ABS_ACCOUNT_KEY: ${{ secrets.ABS_ACCOUNT_KEY }}
  ABS_ACCOUNT_NAME: 7nybfrempo4vcbd4248b7ca
  ABS_CONTAINER_NAME: ${{ github.run_id }}-${{ github.run_number }}
  GITHUB_OAUTH_TOKEN: ${{ secrets.OAUTH_TOKEN_GITHUB }}

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Build docker image
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BUILD_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BUILD_AWS_SECRET_ACCESS_KEY }}
        run: |
          docker-compose build --pull production
          docker save -o /tmp/image.tar php-db-import-export_production:latest
      -
        name: Check
        run: |
          docker-compose run production composer ci
      -
        name: Upload docker image
        uses: actions/upload-artifact@v2
        with:
          name: image
          path: /tmp/image.tar
#
# Load stubs to S3/ABS
  load-s3:
    runs-on: ubuntu-latest
    needs: build
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      -
        name: Load data to ${{ matrix.storage }}
        run: |
          docker-compose run production composer loadS3
  load-abs:
    runs-on: ubuntu-latest
    needs: build
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      -
        name: Load data to ${{ matrix.storage }}
        run: |
          docker-compose run production composer loadAbs
#
# Test matrix
  testsABS:
    runs-on: ubuntu-latest
    needs: load-abs
    concurrency: ${{ matrix.suite }}
    strategy:
      fail-fast: false
      matrix:
        suite:
          - snowflake-abs
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run production composer tests-${{ matrix.suite }}
  testsS3:
    runs-on: ubuntu-latest
    needs: load-s3
    concurrency: ${{ matrix.suite }}
    strategy:
      fail-fast: false
      matrix:
        suite:
          - snowflake-s3
          - teradata-tpt
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run production composer tests-${{ matrix.suite }}
  testsAll:
    runs-on: ubuntu-latest
    needs: [load-s3, load-abs]
    concurrency: ${{ matrix.suite }}
    strategy:
      fail-fast: false
      matrix:
        suite:
          - storage
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run production composer tests-${{ matrix.suite }}

  pre-synapse-tests:
    runs-on: ubuntu-latest
    needs: load-abs
    concurrency: synapse-tests
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Synapse start
        run: |
          bash ./provisioning/scripts/synapseRun.sh -r || exit 1
          bash ./provisioning/scripts/synapseRun.sh -w || exit 1

  synapse-tests:
    runs-on: ubuntu-latest
    needs: pre-synapse-tests
    strategy:
      fail-fast: false
      matrix:
        suite:
          - synapse
          - synapse-mi
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      #
      # TESTS
      #
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run production composer tests-${{ matrix.suite }}
  post-synapse-tests:
    runs-on: ubuntu-latest
    needs: synapse-tests
    if: ${{ always() }}
    concurrency: synapse-tests
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Synapse stop
        if: ${{ always() }}
        run: |
          bash ./provisioning/scripts/synapseRun.sh -p || exit 1

  pre-exasol-tests:
    runs-on: ubuntu-latest
    needs: load-s3
    concurrency: exasol-tests
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Exasol start
        run: |
          bash ./docker/exasol/createDeleteServer.sh -w || exit 1

  exasol-tests:
    runs-on: ubuntu-latest
    needs: pre-exasol-tests
    strategy:
      fail-fast: false
      matrix:
        suite:
          - exasol
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      #
      # TESTS
      #
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run production composer tests-${{ matrix.suite }}
  post-exasol-tests:
    runs-on: ubuntu-latest
    needs: exasol-tests
    if: ${{ always() }}
    concurrency: exasol-tests
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Exasol stop
        if: ${{ always() }}
        run: |
          bash ./docker/exasol/createDeleteServer.sh -p || exit 1

#
# Clean up uploaded data
  clean-data:
    runs-on: ubuntu-latest
    needs: [testsABS, testsS3, testsAll, synapse-tests]
    if: ${{ always() }}
    steps:
      -
        name: 'Clean blob storage'
        uses: azure/CLI@v1
        with:
          inlineScript: |
            az storage container delete \
            --account-key ${{ env.ABS_ACCOUNT_KEY }} \
            --account-name ${{ env.ABS_ACCOUNT_NAME }} \
            --name ${{ env.ABS_CONTAINER_NAME }}
      -
        name: 'Clean S3'
        run: |
          aws s3 rm s3://${{ env.AWS_S3_BUCKET }}/${{env.AWS_S3_KEY}} --recursive
