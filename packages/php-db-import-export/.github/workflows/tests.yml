name: Tests

on:
  push:
    branches:
      - master
  pull_request:

env:
  TEST_PREFIX: gh_
  # Snowflake
  SNOWFLAKE_HOST: keboolaconnectiondev.us-east-1.snowflakecomputing.com
  SNOWFLAKE_PORT: 443
  SNOWFLAKE_USER: KEBOOLA_CI_PHP_IE_LIB
  SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
  SNOWFLAKE_DATABASE: KEBOOLA_CI_PHP_IE_LIB
  SNOWFLAKE_WAREHOUSE: DEV
  # Synapse
  SYNAPSE_UID: ci-php-ei-lib
  SYNAPSE_PWD: ${{ secrets.SYNAPSE_PWD }}
  SYNAPSE_DATABASE: ci-php-ei-lib
  SYNAPSE_SERVER: ci-php-ei-lib.database.windows.net
  SYNAPSE_SQL_SERVER_NAME: ci-php-ei-lib
  SYNAPSE_DW_SERVER_NAME: ci-php-ei-lib
  # Teradata
  TERADATA_HOST: 20.105.40.100
  TERADATA_USERNAME: ci_ielib
  TERADATA_PASSWORD: ${{ secrets.TERADATA_PASSWORD }}
  TERADATA_PORT: 1025
  TERADATA_DATABASE: ci_ielib
  # Exasol
  EXASOL_HOST: m6xc56lzwffdzb6bvrzqwfn57u.clusters.exasol.com:8563
  EXASOL_USERNAME: jiri_semmler
  EXASOL_PASSWORD: ${{ secrets.EXASOL_PASSWORD }}
  # S3
  AWS_ACCESS_KEY_ID: AKIASFZVQM6IHFATWR4X
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_S3_BUCKET: ci-php-ie-lib
  AWS_S3_KEY: ${{ github.run_id }}-${{ github.run_number }}
  AWS_REGION: us-east-1
  # ABS
  ABS_ACCOUNT_KEY: ${{ secrets.ABS_ACCOUNT_KEY }}
  ABS_ACCOUNT_NAME: cixxxphpxxxiexxxlib
  ABS_CONTAINER_NAME: ${{ github.run_id }}-${{ github.run_number }}
  GITHUB_OAUTH_TOKEN: ${{ secrets.OAUTH_TOKEN_GITHUB }}
  # Azure cli
  AZURE_TENANT_ID: 9b85ee6f-4fb0-4a46-8cb7-4dcc6b262a89
  AZURE_CLIENT_ID: 355a3e15-5251-42a9-8266-85c3e17ae82d
  AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
  AZURE_RESOURCE_GROUP: ci-import-export-lib

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      -
        name: Checkout
        uses: actions/checkout@v2
      -
        name: Build docker image
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BUILD_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BUILD_AWS_SECRET_ACCESS_KEY }}
        run: |
          docker-compose build --pull production
          docker save -o /tmp/image.tar php-db-import-export_production:latest
      -
        name: Check
        run: |
          docker-compose run production composer ci
      -
        name: Upload docker image
        uses: actions/upload-artifact@v2
        with:
          name: image
          path: /tmp/image.tar
#
# Load stubs to S3/ABS
  load-data:
    runs-on: ubuntu-latest
    needs: build
    strategy:
      fail-fast: true
      matrix:
        storage:
          - S3
          - ABS
    steps:
      -
        name: Checkout
        uses: actions/checkout@v2
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      -
        name: Load data to ${{ matrix.storage }}
        run: |
          docker-compose run production composer load${{ matrix.storage }}

#
# Test matrix
  tests:
    runs-on: ubuntu-latest
    needs: load-data
    concurrency: ${{ matrix.suite }}
    strategy:
      fail-fast: false
      matrix:
        suite:
          - storage
          - snowflake-abs
          - snowflake-s3
          - teradata-tpt
    steps:
      -
        name: Checkout
        uses: actions/checkout@v2
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
#
# TESTS
#
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run production composer tests-${{ matrix.suite }}

  pre-synapse-tests:
    runs-on: ubuntu-latest
    needs: load-data
    concurrency: synapse-tests
    steps:
      - name: Azure Login
        uses: azure/login@v1
      -
        name: Synapse start
        uses: azure/CLI@v1
        with:
          inlineScript: |
            az sql dw resume \
            --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
            --server ${{ env.SYNAPSE_SQL_SERVER_NAME }} \
            --name ${{ env.SYNAPSE_DW_SERVER_NAME }}")

  synapse-tests:
    runs-on: ubuntu-latest
    needs: pre-synapse-tests
    strategy:
      fail-fast: false
      matrix:
        suite:
          - synapse
          - synapse-mi
          - synapse
    steps:
      -
        name: Checkout
        uses: actions/checkout@v2
      -
        name: Download artifact
        uses: actions/download-artifact@v2
        with:
          name: image
          path: /tmp
      -
        name: Load Docker image
        run: |
          docker load --input /tmp/image.tar
      #
      # TESTS
      #
      -
        name: Tests ${{ matrix.suite }}
        env:
          SUITE: ${{ matrix.suite }}
        run: docker-compose run production composer tests-${{ matrix.suite }}

  post-synapse-tests:
    runs-on: ubuntu-latest
    needs: synapse-tests
    concurrency: synapse-tests
    steps:
      - name: Azure Login
        uses: azure/login@v1
      -
        name: Synapse stop
        if: ${{ always() }}
        uses: azure/CLI@v1
        with:
          inlineScript: |
            az sql dw pause \
            --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
            --server ${{ env.SYNAPSE_SQL_SERVER_NAME }} \
            --name ${{ env.SYNAPSE_DW_SERVER_NAME }}")
#
# Clean up uploaded data
  clean-data:
    runs-on: ubuntu-latest
    needs: [tests, synapse-tests]
    if: ${{ always() }}
    steps:
      - name: Azure Login
        uses: azure/login@v1
      -
        name: 'Clean blob storage'
        uses: azure/CLI@v1
        with:
          inlineScript: |
            az storage container delete \
            --account-key ${{ env.ABS_ACCOUNT_KEY }} \
            --account-name ${{ env.ABS_ACCOUNT_NAME }} \
            --name ${{ env.ABS_CONTAINER_NAME }}
      -
        name: 'Clean S3'
        run: |
          aws s3 rm s3://${{ env.AWS_S3_BUCKET }}/${{env.AWS_S3_KEY}} --recursive
